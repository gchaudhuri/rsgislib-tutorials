{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a6e2b3-bd96-4b61-8237-b34c74d00709",
   "metadata": {},
   "source": [
    "# Comparing Regressors\n",
    "\n",
    "It is commonly the case that is it no possible to predict which regressor will produce the best results. Therefore, we need to try each of the regressors and compare the results. For this analysis we will not optimise the parameters for the regressors which should be done but this was demonstrated in the previous notebook and significantly increases the compute time for the notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf88c7-ff0b-4a4d-9a43-ec3935cf9d64",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e61c0f-fff1-4f6e-8f50-daa75b38fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import rsgislib.tools.utils\n",
    "import rsgislib.regression.regresssklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d32cc4-fe3a-4dea-9883-dda3b3cdbe08",
   "metadata": {},
   "source": [
    "# 2. Read the input plot data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21719126-d0b3-4080-86ca-9ed710caa91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CSV file as a Pandas data frame - the df variable.\n",
    "df = pandas.read_csv('../data/lidar/Forest_Plot_Metrics_LassoLars_Sel.csv', index_col=0)\n",
    "\n",
    "# Get a list of the columns within the df dataframe\n",
    "cols = list(df.columns)\n",
    "\n",
    "# Get the indepedent predictor column names\n",
    "ind_vars = cols[6:]\n",
    "\n",
    "# Get the dependent response column names\n",
    "dep_vars = cols[3:6]\n",
    "\n",
    "# Get the predictor variables and dependent variables\n",
    "# from the dataframe as numpy arrays\n",
    "x = df[ind_vars].values\n",
    "y = df[dep_vars].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29889690-a0de-4214-8f0d-d8c02dae4f79",
   "metadata": {},
   "source": [
    "# 3. Create output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf0a4d0-d5d6-4bb2-befe-2e66b9a8dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"compare_multivar_reg_outputs\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5f6ee3-c760-462a-86eb-c6c3383f5a1d",
   "metadata": {},
   "source": [
    "# 4. Create Data Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e33abd2a-cfa9-40cd-8a86-42424c78762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a data scaler - will be used for some regressors\n",
    "data_scaler = StandardScaler()\n",
    "data_scaler.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0018de6b-7fa1-48bb-b650-622acbf36dfb",
   "metadata": {},
   "source": [
    "# 5. KFold Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba52449-2b96-4052-892d-0e6f57e5dd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:04, 22.16it/s]\n"
     ]
    }
   ],
   "source": [
    "skregrs_obj = ExtraTreesRegressor()\n",
    "et_metrics, et_residuals = rsgislib.regression.regresssklearn.perform_kfold_fit(skregrs_obj, x, y, n_splits=5, repeats=20, shuffle=False, data_scaler=None)\n",
    "\n",
    "# Write metrics and residuals to files.\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    # Remove spaces (replaced with underscores) and any puntuation from \n",
    "    # the variable name so it can be used within as part of the output \n",
    "    # file name \n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True).lower()\n",
    "    \n",
    "    df_metrics = pandas.DataFrame(data=et_metrics[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(out_dir, \"Forest_Plot_Regres_Metrics_ET_{}.csv\".format(dep_var_chk))\n",
    "    df_metrics.to_csv(out_csv_file)\n",
    "    \n",
    "    df_residuals = pandas.DataFrame(data=et_residuals[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(out_dir, \"Forest_Plot_Regres_Residuals_ET_{}.csv\".format(dep_var_chk))\n",
    "    df_residuals.to_csv(out_csv_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99b7553-d7b9-4c31-8ff6-5d3a805cb5cf",
   "metadata": {},
   "source": [
    "# 6. KFold Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3bed8cb-70a0-4e3a-a15b-035769009c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 540.30it/s]\n"
     ]
    }
   ],
   "source": [
    "skregrs_obj = KernelRidge()\n",
    "kr_metrics, kr_residuals = rsgislib.regression.regresssklearn.perform_kfold_fit(skregrs_obj, x, y, n_splits=5, repeats=20, shuffle=False, data_scaler=None)\n",
    "\n",
    "# Write metrics and residuals to files.\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    # Remove spaces (replaced with underscores) and any puntuation from \n",
    "    # the variable name so it can be used within as part of the output \n",
    "    # file name \n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True).lower()\n",
    "    \n",
    "    df_metrics = pandas.DataFrame(data=kr_metrics[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(out_dir, \"Forest_Plot_Regres_Metrics_KR_{}.csv\".format(dep_var_chk))\n",
    "    df_metrics.to_csv(out_csv_file)\n",
    "    \n",
    "    df_residuals = pandas.DataFrame(data=kr_residuals[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(out_dir, \"Forest_Plot_Regres_Residuals_KR_{}.csv\".format(dep_var_chk))\n",
    "    df_residuals.to_csv(out_csv_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f339047-8057-41ba-a62a-e41634170d55",
   "metadata": {},
   "source": [
    "# 7. KFold ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "718d203e-673e-4d88-a35e-5e1dc725fa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 623.38it/s]\n"
     ]
    }
   ],
   "source": [
    "skregrs_obj = ElasticNet()\n",
    "en_metrics, en_residuals = rsgislib.regression.regresssklearn.perform_kfold_fit(skregrs_obj, x, y, n_splits=5, repeats=20, shuffle=False, data_scaler=None)\n",
    "\n",
    "# Write metrics and residuals to files.\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    # Remove spaces (replaced with underscores) and any puntuation from \n",
    "    # the variable name so it can be used within as part of the output \n",
    "    # file name \n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True).lower()\n",
    "    \n",
    "    df_metrics = pandas.DataFrame(data=en_metrics[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(out_dir, \"Forest_Plot_Regres_Metrics_EN_{}.csv\".format(dep_var_chk))\n",
    "    df_metrics.to_csv(out_csv_file)\n",
    "    \n",
    "    df_residuals = pandas.DataFrame(data=en_residuals[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(out_dir, \"Forest_Plot_Regres_Residuals_EN_{}.csv\".format(dep_var_chk))\n",
    "    df_residuals.to_csv(out_csv_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3986545-8d57-4dc8-baa4-7c0f32bd6f10",
   "metadata": {},
   "source": [
    "# 8. KFold K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e191d53-79b8-43fd-908e-968155b5ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 738.21it/s]\n"
     ]
    }
   ],
   "source": [
    "skregrs_obj = KNeighborsRegressor()\n",
    "knn_metrics, knn_residuals = rsgislib.regression.regresssklearn.perform_kfold_fit(skregrs_obj, x, y, n_splits=5, repeats=20, shuffle=False, data_scaler=data_scaler)\n",
    "\n",
    "# Write metrics and residuals to files.\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    # Remove spaces (replaced with underscores) and any puntuation from \n",
    "    # the variable name so it can be used within as part of the output \n",
    "    # file name \n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True).lower()\n",
    "    \n",
    "    df_metrics = pandas.DataFrame(data=knn_metrics[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(out_dir, \"Forest_Plot_Regres_Metrics_KNN_{}.csv\".format(dep_var_chk))\n",
    "    df_metrics.to_csv(out_csv_file)\n",
    "    \n",
    "    df_residuals = pandas.DataFrame(data=knn_residuals[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(out_dir, \"Forest_Plot_Regres_Residuals_KNN_{}.csv\".format(dep_var_chk))\n",
    "    df_residuals.to_csv(out_csv_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee07c3c-51f5-4cea-91a4-0eedd5d21fdb",
   "metadata": {},
   "source": [
    "# 9. KFold PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc5b081f-8adf-432c-a71f-349b35d0df53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 722.06it/s]\n"
     ]
    }
   ],
   "source": [
    "skregrs_obj = PLSRegression()\n",
    "pls_metrics, pls_residuals = rsgislib.regression.regresssklearn.perform_kfold_fit(skregrs_obj, x, y, n_splits=5, repeats=20, shuffle=False, data_scaler=None)\n",
    "\n",
    "# Write metrics and residuals to files.\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    # Remove spaces (replaced with underscores) and any puntuation from \n",
    "    # the variable name so it can be used within as part of the output \n",
    "    # file name \n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True).lower()\n",
    "    \n",
    "    df_metrics = pandas.DataFrame(data=pls_metrics[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(out_dir, \"Forest_Plot_Regres_Metrics_PLS_{}.csv\".format(dep_var_chk))\n",
    "    df_metrics.to_csv(out_csv_file)\n",
    "    \n",
    "    df_residuals = pandas.DataFrame(data=pls_residuals[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(out_dir, \"Forest_Plot_Regres_Residuals_PLS_{}.csv\".format(dep_var_chk))\n",
    "    df_residuals.to_csv(out_csv_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef568289-3573-4569-bb7a-3e32e95fc616",
   "metadata": {},
   "source": [
    "# 10. KFold Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7519297-67ec-4269-917a-c31a2d0f96a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 877.50it/s]\n"
     ]
    }
   ],
   "source": [
    "skregrs_obj = LinearRegression()\n",
    "ols_metrics, ols_residuals = rsgislib.regression.regresssklearn.perform_kfold_fit(skregrs_obj, x, y, n_splits=5, repeats=20, shuffle=False, data_scaler=None)\n",
    "\n",
    "# Write metrics and residuals to files.\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    # Remove spaces (replaced with underscores) and any puntuation from \n",
    "    # the variable name so it can be used within as part of the output \n",
    "    # file name \n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True).lower()\n",
    "    \n",
    "    df_metrics = pandas.DataFrame(data=ols_metrics[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(out_dir, \"Forest_Plot_Regres_Metrics_OLS_{}.csv\".format(dep_var_chk))\n",
    "    df_metrics.to_csv(out_csv_file)\n",
    "    \n",
    "    df_residuals = pandas.DataFrame(data=ols_residuals[i])\n",
    "    # Save the dataframe to a CSV file.\n",
    "    out_csv_file = os.path.join(out_dir, \"Forest_Plot_Regres_Residuals_OLS_{}.csv\".format(dep_var_chk))\n",
    "    df_residuals.to_csv(out_csv_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7b7587-5574-4c8a-b23b-5d5785fd0df1",
   "metadata": {},
   "source": [
    "# 11. Summarising the Regression Statistics\n",
    "\n",
    "The next step is to summarise metrics we have just outputted from the kfold regressions above so we can try and understand which of the regression algorithms has given us the best result. \n",
    "\n",
    "For this analysis we want to summarise each individual set of outputs for each algorithm and dependent variable and then create summary tables we can use to aid the identification of the algorithm to take forward as the **'best'** and for application to the image data. In this case, we will use the following metrics to summarise the results:\n",
    "\n",
    " 1. The coefficient of determination (r2),\n",
    " 2. Root Mean Square Error (RMSE),\n",
    " 3. Normalised Root Mean Square Error (nRMSE),\n",
    " 4. Bias.\n",
    " 5. Normalised Bias\n",
    "\n",
    "The first step is to take all the outputs and merge them into a single table for each depedent variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87522580-2168-477a-9501-1410c4413bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean DBH\n",
      "\tET\n",
      "\tKR\n",
      "\tEN\n",
      "\tKNN\n",
      "\tPLS\n",
      "\tOLS\n",
      "BA / ha\n",
      "\tET\n",
      "\tKR\n",
      "\tEN\n",
      "\tKNN\n",
      "\tPLS\n",
      "\tOLS\n",
      "Vol / ha\n",
      "\tET\n",
      "\tKR\n",
      "\tEN\n",
      "\tKNN\n",
      "\tPLS\n",
      "\tOLS\n"
     ]
    }
   ],
   "source": [
    "regress_alg = [\"ET\", \"KR\", \"EN\", \"KNN\", \"PLS\", \"OLS\"]\n",
    "regress_metrics = [et_metrics, kr_metrics, en_metrics, knn_metrics, pls_metrics, ols_metrics]\n",
    "\n",
    "# Using the aggregate function in Pandas we can specify a list of summary statistics for each column\n",
    "regrs_metrics_sum_stats = {\n",
    "    \"r2\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"explained_variance_score\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"median_absolute_error\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"mean_absolute_error\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"mean_squared_error\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"root_mean_squared_error\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"norm_root_mean_squared_error\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"bias\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"norm_bias\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"bias_squared\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"variance\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"],\n",
    "    \"noise\": [\"min\", \"max\", \"mean\", \"median\", \"std\", \"var\"]\n",
    "}\n",
    "\n",
    "out_summary_stats = dict()\n",
    "\n",
    "for i, dep_var in enumerate(dep_vars):\n",
    "    print(dep_var)\n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True).lower()\n",
    "    \n",
    "    rmse_sum_stats = dict()\n",
    "    rmse_sum_stats['mean'] = list()\n",
    "    rmse_sum_stats['median'] = list()\n",
    "    rmse_sum_stats['std'] = list()\n",
    "    rmse_sum_stats['stderr'] = list()\n",
    "    rmse_sum_stats['conf95'] = list()\n",
    "    \n",
    "    nrmse_sum_stats = dict()\n",
    "    nrmse_sum_stats['mean'] = list()\n",
    "    nrmse_sum_stats['median'] = list()\n",
    "    nrmse_sum_stats['std'] = list()\n",
    "    nrmse_sum_stats['stderr'] = list()\n",
    "    nrmse_sum_stats['conf95'] = list()\n",
    "    \n",
    "    r2_sum_stats = dict()\n",
    "    r2_sum_stats['mean'] = list()\n",
    "    r2_sum_stats['median'] = list()\n",
    "    r2_sum_stats['std'] = list()\n",
    "    r2_sum_stats['stderr'] = list()\n",
    "    r2_sum_stats['conf95'] = list()\n",
    "    \n",
    "    bias_sum_stats = dict()\n",
    "    bias_sum_stats['mean'] = list()\n",
    "    bias_sum_stats['median'] = list()\n",
    "    bias_sum_stats['std'] = list()\n",
    "    bias_sum_stats['stderr'] = list()\n",
    "    bias_sum_stats['conf95'] = list()\n",
    "    \n",
    "    nbias_sum_stats = dict()\n",
    "    nbias_sum_stats['mean'] = list()\n",
    "    nbias_sum_stats['median'] = list()\n",
    "    nbias_sum_stats['std'] = list()\n",
    "    nbias_sum_stats['stderr'] = list()\n",
    "    nbias_sum_stats['conf95'] = list()\n",
    "    \n",
    "    for metrics, alg in zip(regress_metrics, regress_alg):\n",
    "        print(f\"\\t{alg}\")\n",
    "        # Create pandas dataframe for the metrics.\n",
    "        df_var_metrics = pandas.DataFrame(data=metrics[i])\n",
    "        # Get the number of samples\n",
    "        n_smps = df_var_metrics.shape[0]\n",
    "        # Calculate the summary statistics (see regrs_metrics_sum_stats\n",
    "        # for the list of stats to be calculated\n",
    "        df_var_sum_stats = df_var_metrics.agg(regrs_metrics_sum_stats).T\n",
    "        \n",
    "        # Calculate additional summary statistics:\n",
    "        # Stand Error and 95th and 99th confidence intervals\n",
    "        df_var_sum_stats['stderr'] = df_var_sum_stats['std'] / numpy.sqrt(n_smps)\n",
    "        df_var_sum_stats['conf95'] = 1.960 * df_var_sum_stats['stderr']\n",
    "        df_var_sum_stats['conf99'] = 2.576 * df_var_sum_stats['stderr']\n",
    "        \n",
    "        # Transpose the dataframe to make it easier to read.\n",
    "        df_var_sum_stats = df_var_sum_stats.T\n",
    "\n",
    "        # Add RMSE values for overall summary statistics table\n",
    "        rmse_sum_stats['mean'].append(df_var_sum_stats['root_mean_squared_error']['mean'])\n",
    "        rmse_sum_stats['median'].append(df_var_sum_stats['root_mean_squared_error']['median'])\n",
    "        rmse_sum_stats['std'].append(df_var_sum_stats['root_mean_squared_error']['std'])\n",
    "        rmse_sum_stats['stderr'].append(df_var_sum_stats['root_mean_squared_error']['stderr'])\n",
    "        rmse_sum_stats['conf95'].append(df_var_sum_stats['root_mean_squared_error']['conf95'])\n",
    "        \n",
    "        # Add normalised RMSE values for overall summary statistics table\n",
    "        nrmse_sum_stats['mean'].append(df_var_sum_stats['norm_root_mean_squared_error']['mean'])\n",
    "        nrmse_sum_stats['median'].append(df_var_sum_stats['norm_root_mean_squared_error']['median'])\n",
    "        nrmse_sum_stats['std'].append(df_var_sum_stats['norm_root_mean_squared_error']['std'])\n",
    "        nrmse_sum_stats['stderr'].append(df_var_sum_stats['norm_root_mean_squared_error']['stderr'])\n",
    "        nrmse_sum_stats['conf95'].append(df_var_sum_stats['norm_root_mean_squared_error']['conf95'])\n",
    "        \n",
    "        # Add r2 values for overall summary statistics table\n",
    "        r2_sum_stats['mean'].append(df_var_sum_stats['r2']['mean'])\n",
    "        r2_sum_stats['median'].append(df_var_sum_stats['r2']['median'])\n",
    "        r2_sum_stats['std'].append(df_var_sum_stats['r2']['std'])\n",
    "        r2_sum_stats['stderr'].append(df_var_sum_stats['r2']['stderr'])\n",
    "        r2_sum_stats['conf95'].append(df_var_sum_stats['r2']['conf95'])\n",
    "        \n",
    "        # Add bias values for overall summary statistics table\n",
    "        bias_sum_stats['mean'].append(df_var_sum_stats['bias']['mean'])\n",
    "        bias_sum_stats['median'].append(df_var_sum_stats['bias']['median'])\n",
    "        bias_sum_stats['std'].append(df_var_sum_stats['bias']['std'])\n",
    "        bias_sum_stats['stderr'].append(df_var_sum_stats['bias']['stderr'])\n",
    "        bias_sum_stats['conf95'].append(df_var_sum_stats['bias']['conf95'])\n",
    "        \n",
    "        # Add normalised bias values for overall summary statistics table\n",
    "        nbias_sum_stats['mean'].append(df_var_sum_stats['norm_bias']['mean'])\n",
    "        nbias_sum_stats['median'].append(df_var_sum_stats['norm_bias']['median'])\n",
    "        nbias_sum_stats['std'].append(df_var_sum_stats['norm_bias']['std'])\n",
    "        nbias_sum_stats['stderr'].append(df_var_sum_stats['norm_bias']['stderr'])\n",
    "        nbias_sum_stats['conf95'].append(df_var_sum_stats['norm_bias']['conf95'])\n",
    "        \n",
    "    # Create a pandas dataframe and write out a CSV file for the RMSE over summary\n",
    "    df_rmse_sum_stats = pandas.DataFrame(data=rmse_sum_stats, index=regress_alg)\n",
    "    out_csv_file = os.path.join(out_dir, \"{}_rmse_overall_summary.csv\".format(dep_var_chk))\n",
    "    df_rmse_sum_stats.to_csv(out_csv_file)\n",
    "    \n",
    "    # Create a pandas dataframe and write out a CSV file for the normalised RMSE over summary\n",
    "    df_nrmse_sum_stats = pandas.DataFrame(data=nrmse_sum_stats, index=regress_alg)\n",
    "    out_csv_file = os.path.join(out_dir, \"{}_nrmse_overall_summary.csv\".format(dep_var_chk))\n",
    "    df_nrmse_sum_stats.to_csv(out_csv_file)\n",
    "    \n",
    "    # Create a pandas dataframe and write out a CSV file for the r2 over summary\n",
    "    df_r2_sum_stats = pandas.DataFrame(data=r2_sum_stats, index=regress_alg)\n",
    "    out_csv_file = os.path.join(out_dir, \"{}_r2_overall_summary.csv\".format(dep_var_chk))\n",
    "    df_r2_sum_stats.to_csv(out_csv_file)\n",
    "    \n",
    "    # Create a pandas dataframe and write out a CSV file for the bias over summary\n",
    "    df_bias_sum_stats = pandas.DataFrame(data=bias_sum_stats, index=regress_alg)\n",
    "    out_csv_file = os.path.join(out_dir, \"{}_bias_overall_summary.csv\".format(dep_var_chk))\n",
    "    df_bias_sum_stats.to_csv(out_csv_file)\n",
    "    \n",
    "    # Create a pandas dataframe and write out a CSV file for the normalised bias over summary\n",
    "    df_nbias_sum_stats = pandas.DataFrame(data=nbias_sum_stats, index=regress_alg)\n",
    "    out_csv_file = os.path.join(out_dir, \"{}_nbias_overall_summary.csv\".format(dep_var_chk))\n",
    "    df_nbias_sum_stats.to_csv(out_csv_file)\n",
    "    \n",
    "    out_summary_stats[dep_var] = {\"rmse\": df_rmse_sum_stats, \"nrmse\": df_nrmse_sum_stats, \"r2\": df_r2_sum_stats, \"bias\": df_bias_sum_stats, \"nbias\": df_nbias_sum_stats}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a663c-5671-4981-b4cb-e3d31e524a81",
   "metadata": {
    "tags": []
   },
   "source": [
    "The previous code created summary files and dataframes, lets now format those into tables for us to interpret, including rounding the numbers to make them more readable. We will also save those tables to CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d7f9a2-074a-4307-83d6-4777ecd5e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean DBH\n",
      "\trmse\n",
      "\tnrmse\n",
      "\tr2\n",
      "\tbias\n",
      "\tnbias\n",
      "BA / ha\n",
      "\trmse\n",
      "\tnrmse\n",
      "\tr2\n",
      "\tbias\n",
      "\tnbias\n",
      "Vol / ha\n",
      "\trmse\n",
      "\tnrmse\n",
      "\tr2\n",
      "\tbias\n",
      "\tnbias\n"
     ]
    }
   ],
   "source": [
    "summary_median_tabs = dict()\n",
    "\n",
    "for dep_var in dep_vars:\n",
    "    print(dep_var)\n",
    "    sum_stats = dict()\n",
    "    for stat in out_summary_stats[dep_var]:\n",
    "        print(f\"\\t{stat}\")\n",
    "        var_df = out_summary_stats[dep_var][stat]\n",
    "        sum_stats[stat] = var_df[\"median\"].round(3)\n",
    "    summary_median_tabs[dep_var] = pandas.DataFrame(data=sum_stats)\n",
    "    dep_var_chk = rsgislib.tools.utils.check_str(dep_var, rm_non_ascii=True, rm_dashs=True, rm_spaces=True, rm_punc=True).lower()\n",
    "    out_csv_file = os.path.join(out_dir, f\"{dep_var_chk}_alg_compare_stats.csv\")\n",
    "    summary_median_tabs[dep_var].to_csv(out_csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9983b33-7ca8-434c-acfe-5357425ea47c",
   "metadata": {},
   "source": [
    "Now lets view those summary tables, sorted by the normalised RMSE (try sorting by the other columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38a6285e-a495-4e02-90da-6d967a8a1d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>bias</th>\n",
       "      <th>nbias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ET</th>\n",
       "      <td>2.996</td>\n",
       "      <td>17.849</td>\n",
       "      <td>0.761</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KR</th>\n",
       "      <td>3.265</td>\n",
       "      <td>18.933</td>\n",
       "      <td>0.737</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>3.267</td>\n",
       "      <td>19.074</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>3.323</td>\n",
       "      <td>19.217</td>\n",
       "      <td>0.733</td>\n",
       "      <td>-0.509</td>\n",
       "      <td>-3.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td>3.335</td>\n",
       "      <td>19.486</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>3.565</td>\n",
       "      <td>20.775</td>\n",
       "      <td>0.692</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rmse   nrmse     r2   bias  nbias\n",
       "ET   2.996  17.849  0.761 -0.093 -0.557\n",
       "KR   3.265  18.933  0.737 -0.042 -0.259\n",
       "OLS  3.267  19.074  0.753  0.052  0.292\n",
       "KNN  3.323  19.217  0.733 -0.509 -3.062\n",
       "EN   3.335  19.486  0.710  0.030  0.176\n",
       "PLS  3.565  20.775  0.692 -0.080 -0.454"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_median_tabs[\"Mean DBH\"].sort_values(\"nrmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "938096f3-7655-4271-895f-b5721cdf9471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>bias</th>\n",
       "      <th>nbias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ET</th>\n",
       "      <td>7.569</td>\n",
       "      <td>20.928</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>7.371</td>\n",
       "      <td>20.965</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KR</th>\n",
       "      <td>7.471</td>\n",
       "      <td>21.270</td>\n",
       "      <td>0.837</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>-0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>7.719</td>\n",
       "      <td>21.650</td>\n",
       "      <td>0.824</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>8.251</td>\n",
       "      <td>23.076</td>\n",
       "      <td>0.804</td>\n",
       "      <td>-0.949</td>\n",
       "      <td>-2.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td>8.375</td>\n",
       "      <td>24.074</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rmse   nrmse     r2   bias  nbias\n",
       "ET   7.569  20.928  0.841  0.041  0.112\n",
       "PLS  7.371  20.965  0.842  0.040  0.104\n",
       "KR   7.471  21.270  0.837 -0.172 -0.508\n",
       "OLS  7.719  21.650  0.824 -0.257 -0.655\n",
       "KNN  8.251  23.076  0.804 -0.949 -2.675\n",
       "EN   8.375  24.074  0.794  0.079  0.234"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_median_tabs[\"BA / ha\"].sort_values(\"nrmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca45d594-0c9a-42c7-b705-6e616b76a9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>bias</th>\n",
       "      <th>nbias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ET</th>\n",
       "      <td>61.066</td>\n",
       "      <td>22.269</td>\n",
       "      <td>0.906</td>\n",
       "      <td>-1.534</td>\n",
       "      <td>-0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td>62.896</td>\n",
       "      <td>22.567</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KR</th>\n",
       "      <td>62.903</td>\n",
       "      <td>22.609</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>62.291</td>\n",
       "      <td>22.985</td>\n",
       "      <td>0.890</td>\n",
       "      <td>-0.928</td>\n",
       "      <td>-0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>68.295</td>\n",
       "      <td>24.637</td>\n",
       "      <td>0.878</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>-0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>72.785</td>\n",
       "      <td>26.507</td>\n",
       "      <td>0.861</td>\n",
       "      <td>-16.861</td>\n",
       "      <td>-6.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rmse   nrmse     r2    bias  nbias\n",
       "ET   61.066  22.269  0.906  -1.534 -0.549\n",
       "EN   62.896  22.567  0.899   0.286  0.110\n",
       "KR   62.903  22.609  0.896   0.466  0.187\n",
       "OLS  62.291  22.985  0.890  -0.928 -0.361\n",
       "PLS  68.295  24.637  0.878  -0.887 -0.350\n",
       "KNN  72.785  26.507  0.861 -16.861 -6.002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_median_tabs[\"Vol / ha\"].sort_values(\"nrmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c23ba0-5ca4-4dea-9c9c-dc6f7191fb11",
   "metadata": {},
   "source": [
    "# 12. So, which is 'best'\n",
    "\n",
    "*Note. Your results might differ slightly from mine as the kfold will produce slightly different results for each run as the splits will be different.*\n",
    "\n",
    "Looking at these tables we can see that for Mean DBH the Extra Trees Regressor has produced the best result with a nRMSE of 17.8 % following by Linear Regression with a nRMSE of 18.9 %. For Basal Area, Extra Trees provided the best result (nRMSE: 21.0 %) followed by PLSRegression (nRMSE: 21.0 %). While for stand volume Extra Trees also provided the best result (NRMSE: 22.3 %) with the KernelRidge regressor (nRMSE: 22.3 %). \n",
    "\n",
    "Therefore we would take forward the Extra Trees result as the regressor to use for further analysis. However, it is worth noting that \n",
    "\n",
    " 1. We did not optimise the parameters of the algorithms and if we had done so then the results might have been different - why don't you try to implement this yourself?\n",
    " 2. The LinearRegressor (OLS) is a much similar model and also produced results which are similar to those of the other algorithms and while it has not produced the best result is it often deseriable to use a simpler model.\n",
    " 3. Becareful of using a model for where inputs are outside of the range of values which used to train the model as there is no guareentee that the results will be valid and it some cases the outputs completely wrong. However, simpler linear models are less likely to produce values which are completely crazy and therefore might be desriable from that point of view.\n",
    "\n",
    "Where you have results which are close then it might also be useful to consider the residuals visualing those to consider the bias.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
